{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a91b6308-6ff7-42a1-8594-0d77d30a02a6",
   "metadata": {},
   "source": [
    "# Claim 2.1: HS improves predictive performance of RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8804370-3cb8-4b4f-a276-7a14c13ae51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# basic data science utilities\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# basic system utilities \n",
    "import os\n",
    "import sys\n",
    "\n",
    "# datasets used by authors in paper\n",
    "import imodels\n",
    "from imodels.util.data_util import get_clean_dataset # this was used to get the datasets\n",
    "\n",
    "# copying Random Forests (RF) so that I can use HS on them (not used because imodels already implements a way to run HS on RFs)\n",
    "# from copy import deepcopy\n",
    "\n",
    "# sklearn baseline random forest \n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "# cross-validation of models & model evaluation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, auc, make_scorer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# hyperparameter tunnning\n",
    "from skopt import gp_minimize\n",
    "\n",
    "# hierarchical shrinkage\n",
    "from imodels import HSTreeClassifier, HSTreeClassifierCV \n",
    "\n",
    "# bayesian-additive regression models (BART)\n",
    "from bartpy.sklearnmodel import SklearnModel\n",
    "\n",
    "# timing algorithm execution\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9038aaa-608a-40eb-aee8-a3ad20395e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets used in paper (location in author repo: github.com/Yu-Group/imodels-experiments/config/shrinkage/models.py)\n",
    "\n",
    "DATASETS_CLASSIFICATION = [\n",
    "    # classification datasets from original random forests paper\n",
    "    # page 9: https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf\n",
    "    (\"heart\", \"heart\", 'imodels'),\n",
    "    (\"breast-cancer\", \"breast_cancer\", 'imodels'),\n",
    "    (\"haberman\", \"haberman\", 'imodels'),\n",
    "    (\"ionosphere\", \"ionosphere\", 'pmlb'),\n",
    "    (\"diabetes\", \"diabetes\", \"pmlb\"),\n",
    "    (\"german-credit\", \"german\", \"pmlb\"),\n",
    "    (\"juvenile\", \"juvenile_clean\", 'imodels'),\n",
    "    (\"recidivism\", \"compas_two_year_clean\", 'imodels')\n",
    "]\n",
    "\n",
    "DATASETS_REGRESSION = [\n",
    "    # leo-breiman paper random forest uses some UCI datasets as well\n",
    "    # pg 23: https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf\n",
    "    ('friedman1', 'friedman1', 'synthetic'),\n",
    "    ('friedman2', 'friedman2', 'synthetic'),\n",
    "    ('friedman3', 'friedman3', 'synthetic'),\n",
    "    ('abalone', '183', 'openml'),\n",
    "    (\"diabetes-regr\", \"diabetes\", 'sklearn'),\n",
    "    (\"california-housing\", \"california_housing\", 'sklearn'),  # this replaced boston-housing due to ethical issues\n",
    "    (\"satellite-image\", \"294_satellite_image\", 'pmlb'),\n",
    "    (\"echo-months\", \"1199_BNG_echoMonths\", 'pmlb'),\n",
    "    (\"breast-tumor\", \"1201_BNG_breastTumor\", 'pmlb'),  # this one is v big (100k examples)\n",
    "\n",
    "]\n",
    "\n",
    "# load datasets (datasets of authors seem to already be preprocessed so we will use theirs)\n",
    "tasks = {}\n",
    "\n",
    "for task in DATASETS_CLASSIFICATION:\n",
    "    X, y, feature_names = get_clean_dataset(task[1], data_source = task[2])\n",
    "    df = pd.DataFrame(X, columns=feature_names)\n",
    "    df[\"label\"] = y\n",
    "    tasks[task[0]] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ffd2b7-613c-4fc1-9603-551ba4569ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: breast-cancer, Sample: 0, Fold 0\r"
     ]
    }
   ],
   "source": [
    "# dataframe to save performance of models\n",
    "classification_results = pd.DataFrame(columns = [\"task\", \"dataset\", \"boot_iter\", \"algorithm\", \"scoring\", \"n_trees\", \"regularization\", \"train_score\", \"test_score\", \\\n",
    "                                                 \"train_wall_time\", \"test_wall_time\", \"train_cpu_time\", \"test_cpu_time\", \"tunning_wall_time\", \"tunning_cpu_time\"])\n",
    "\n",
    "# number of leafs used in paper\n",
    "num_of_trees = [10, 25, 50, 75, 100, 300, 500]\n",
    "\n",
    "# regularization parameter\n",
    "reg_hs = [0.1, 1.0, 10.0, 25.0, 50.0, 100.0]\n",
    "\n",
    "# number of times to repeat evaluations with random splits (5 repeats with 3-fold cross-validation = 15 repeats)\n",
    "NUM_OF_BOOTSTRAP_SAMPS = 5\n",
    "\n",
    "# for each dataset that was used in paper\n",
    "for task in DATASETS_CLASSIFICATION:\n",
    "    # repeat NUM_OF_BOOTSTRAP_SAMPS\n",
    "    for samp in range(NUM_OF_BOOTSTRAP_SAMPS):\n",
    "        # use statified splitting (we tried both stratified and un-stratified => no significant differences)\n",
    "        skf = StratifiedKFold(n_splits=3)\n",
    "         \n",
    "        X, y = np.array(tasks[task[0]].drop(\"label\", axis = 1)), np.array(tasks[task[0]][\"label\"])\n",
    "        \n",
    "        # cross-validation loop\n",
    "        for i, (train_index, test_index) in enumerate(skf.split(tasks[task[0]], tasks[task[0]][\"label\"])):\n",
    "            print(f\"Dataset: {task[0]}, Sample: {samp}, Fold {i}\", end = \"\\r\")\n",
    "\n",
    "            X_train, y_train = X[train_index, :], y[train_index]\n",
    "            X_test, y_test = X[test_index, :], y[test_index]\n",
    "\n",
    "            # for each tree (as deduced from fig. 4D)\n",
    "            for m in num_of_trees:\n",
    "                \n",
    "                ### Random Forest (RF) ###\n",
    "                \n",
    "                # measure train time\n",
    "                start_wall_time_train = time.time()\n",
    "                start_cpu_time_train = time.process_time()\n",
    "                \n",
    "                rf = RandomForestClassifier(n_estimators=m, max_features = \"sqrt\").fit(X_train, y_train)\n",
    "                \n",
    "                end_wall_time_train = time.time()\n",
    "                end_cpu_time_train = time.process_time()\n",
    "                \n",
    "                # measure test time\n",
    "                start_wall_time_test = time.time()\n",
    "                start_cpu_time_test = time.process_time()\n",
    "                \n",
    "                y_train_pred_rf = rf.predict(X_train)\n",
    "                y_test_pred_rf = rf.predict(X_test)\n",
    "                \n",
    "                end_wall_time_test = time.time()\n",
    "                end_cpu_time_test = time.process_time()\n",
    "\n",
    "                classification_results = pd.concat([classification_results, pd.DataFrame({\"task\": [\"classification\"], \n",
    "                                                                            \"dataset\": [task[0]],\n",
    "                                                                            \"boot_iter\": [samp],\n",
    "                                                                            \"algorithm\": [\"RF\"],\n",
    "                                                                            \"scoring\": [\"AUC\"],\n",
    "                                                                            \"n_trees\": [m],\n",
    "                                                                            \"regularization\": [\"None\"],\n",
    "                                                                            \"train_score\": [roc_auc_score(y_train, y_train_pred_rf)],\n",
    "                                                                            \"test_score\": [roc_auc_score(y_test, y_test_pred_rf)],\n",
    "                                                                            \"train_wall_time\": [end_wall_time_train - start_wall_time_train],\n",
    "                                                                            \"test_wall_time\": [end_wall_time_test - start_wall_time_test],\n",
    "                                                                            \"train_cpu_time\": [end_cpu_time_train - start_cpu_time_train],\n",
    "                                                                            \"test_cpu_time\": [end_cpu_time_test - start_cpu_time_test],\n",
    "                                                                            \"tunning_wall_time\": [None], \n",
    "                                                                            \"tunning_cpu_time\": [None]})])\n",
    "                \n",
    "                ### RF-CV (max_features (mtry)) ###                \n",
    "                \n",
    "                # tunning function to use in gp_minimize\n",
    "                def rf_mtry(mtry):\n",
    "                    rf_mtry = RandomForestClassifier(n_estimators=m, max_features = mtry[0])\n",
    "                    roc_spec = make_scorer(roc_auc_score, needs_proba=True)\n",
    "                    scores = cross_val_score(rf_mtry, X_train, y_train, cv=3, scoring = roc_spec)\n",
    "                    return -np.mean(scores)\n",
    "                \n",
    "                # measure tunning time\n",
    "                start_wall_time_tunning = time.time()\n",
    "                start_cpu_time_tunning = time.process_time()\n",
    "                \n",
    "                mtry_best = gp_minimize(rf_mtry,\n",
    "                            [(0.1, 1.0)],\n",
    "                            acq_func=\"EI\",\n",
    "                            n_calls = 15,\n",
    "                            n_initial_points = 5,\n",
    "                            noise = 0.1**2).x[0]\n",
    "                \n",
    "                end_wall_time_tunning = time.time()\n",
    "                end_cpu_time_tunning = time.process_time()\n",
    "                \n",
    "                # measure train time\n",
    "                start_wall_time_train = time.time()\n",
    "                start_cpu_time_train = time.process_time()\n",
    "                \n",
    "                rf_mtry = RandomForestClassifier(n_estimators=m, max_features = mtry_best).fit(X_train, y_train)\n",
    "                \n",
    "                end_wall_time_train = time.time()\n",
    "                end_cpu_time_train = time.process_time()\n",
    "                \n",
    "                # measure test time\n",
    "                start_wall_time_test = time.time()\n",
    "                start_cpu_time_test = time.process_time()\n",
    "                \n",
    "                y_train_pred_rf_mtry = rf_mtry.predict(X_train)\n",
    "                y_test_pred_rf_mtry = rf_mtry.predict(X_test)\n",
    "                \n",
    "                end_wall_time_test = time.time()\n",
    "                end_cpu_time_test = time.process_time()\n",
    "\n",
    "                classification_results = pd.concat([classification_results, pd.DataFrame({\"task\": [\"classification\"], \n",
    "                                                                            \"dataset\": [task[0]],\n",
    "                                                                            \"boot_iter\": [samp],\n",
    "                                                                            \"algorithm\": [\"RF-MTRY\"],\n",
    "                                                                            \"scoring\": [\"AUC\"],\n",
    "                                                                            \"n_trees\": [m],\n",
    "                                                                            \"regularization\": [rf_mtry], # we store best mtry parameter in regularization\n",
    "                                                                            \"train_score\": [roc_auc_score(y_train, y_train_pred_rf_mtry)],\n",
    "                                                                            \"test_score\": [roc_auc_score(y_test, y_test_pred_rf_mtry)],\n",
    "                                                                            \"train_wall_time\": [end_wall_time_train - start_wall_time_train],\n",
    "                                                                            \"test_wall_time\": [end_wall_time_test - start_wall_time_test],\n",
    "                                                                            \"train_cpu_time\": [end_cpu_time_train - start_cpu_time_train],\n",
    "                                                                            \"test_cpu_time\": [end_cpu_time_test - start_cpu_time_test],\n",
    "                                                                            \"tunning_wall_time\": [end_wall_time_tunning - start_wall_time_tunning], \n",
    "                                                                            \"tunning_cpu_time\": [end_cpu_time_tunning - start_cpu_time_tunning]})])\n",
    "                \n",
    "                ### RF-CV (max_depth (depth)) ###\n",
    "                def rf_depth(depth):\n",
    "                    rf_depth = RandomForestClassifier(n_estimators=m, max_depth = int(np.round(depth[0])))\n",
    "                    roc_spec = make_scorer(roc_auc_score, needs_proba=True)\n",
    "                    scores = cross_val_score(rf_depth, X_train, y_train, cv=3, scoring = roc_spec)\n",
    "                    return -np.mean(scores)\n",
    "                \n",
    "                # measure tunning time\n",
    "                start_wall_time_tunning = time.time()\n",
    "                start_cpu_time_tunning = time.process_time()\n",
    "                \n",
    "                depth_best = int(np.round(gp_minimize(rf_depth,\n",
    "                            [(1.0, 30.0)],\n",
    "                            acq_func=\"EI\",\n",
    "                            n_calls = 15,\n",
    "                            n_initial_points = 5,\n",
    "                            noise = 0.1**2).x[0]))\n",
    "                \n",
    "                end_wall_time_tunning = time.time()\n",
    "                end_cpu_time_tunning = time.process_time()\n",
    "                \n",
    "                # measure train time\n",
    "                start_wall_time_train = time.time()\n",
    "                start_cpu_time_train = time.process_time()\n",
    "                \n",
    "                rf_depth = RandomForestClassifier(n_estimators=m, max_depth = depth_best).fit(X_train, y_train)\n",
    "                \n",
    "                end_wall_time_train = time.time()\n",
    "                end_cpu_time_train = time.process_time()\n",
    "                \n",
    "                # measure test time\n",
    "                start_wall_time_test = time.time()\n",
    "                start_cpu_time_test = time.process_time()\n",
    "                \n",
    "                y_train_pred_rf_depth = rf_depth.predict(X_train)                \n",
    "                y_test_pred_rf_depth = rf_depth.predict(X_test)\n",
    "                \n",
    "                end_wall_time_test = time.time()\n",
    "                end_cpu_time_test = time.process_time()\n",
    "\n",
    "                classification_results = pd.concat([classification_results, pd.DataFrame({\"task\": [\"classification\"], \n",
    "                                                                            \"dataset\": [task[0]],\n",
    "                                                                            \"boot_iter\": [samp],\n",
    "                                                                            \"algorithm\": [\"RF-DEPTH\"],\n",
    "                                                                            \"scoring\": [\"AUC\"],\n",
    "                                                                            \"n_trees\": [m],\n",
    "                                                                            \"regularization\": [rf_depth], # we store best depth parameter in regularization\n",
    "                                                                            \"train_score\": [roc_auc_score(y_train, y_train_pred_rf_depth)],\n",
    "                                                                            \"test_score\": [roc_auc_score(y_test, y_test_pred_rf_depth)],\n",
    "                                                                            \"train_wall_time\": [end_wall_time_train - start_wall_time_train],\n",
    "                                                                            \"test_wall_time\": [end_wall_time_test - start_wall_time_test],\n",
    "                                                                            \"train_cpu_time\": [end_cpu_time_train - start_cpu_time_train],\n",
    "                                                                            \"test_cpu_time\": [end_cpu_time_test - start_cpu_time_test],\n",
    "                                                                            \"tunning_wall_time\": [end_wall_time_tunning - start_wall_time_tunning], \n",
    "                                                                            \"tunning_cpu_time\": [end_cpu_time_tunning - start_cpu_time_tunning]})])\n",
    "                \n",
    "                ### HS-RF (hierarchical shrinkage) ###\n",
    "                \n",
    "                # measure tunning time\n",
    "                start_wall_time_tunning = time.time()\n",
    "                start_cpu_time_tunning = time.process_time()\n",
    "                \n",
    "                roc_spec = make_scorer(roc_auc_score)\n",
    "                rf = RandomForestClassifier(n_estimators=m, max_features = \"sqrt\")\n",
    "                hs_rf_cv = HSTreeClassifierCV(estimator_=rf, reg_param_list = reg_hs, cv = 3, scoring = roc_spec)\n",
    "                hs_rf_cv.fit(X_train, y_train)\n",
    "                \n",
    "                best_hs_reg = hs_rf_cv.reg_param\n",
    "                \n",
    "                end_wall_time_tunning = time.time()\n",
    "                end_cpu_time_tunning = time.process_time()\n",
    "                \n",
    "                # measure train time\n",
    "                start_wall_time_train = time.time()\n",
    "                start_cpu_time_train = time.process_time()\n",
    "                \n",
    "                rf = RandomForestClassifier(n_estimators=m, max_features = \"sqrt\")\n",
    "                hs_rf = HSTreeClassifier(estimator_= rf, reg_param = best_hs_reg) \n",
    "                hs_rf.fit(X_train, y_train)\n",
    "                \n",
    "                end_wall_time_train = time.time()\n",
    "                end_cpu_time_train = time.process_time()\n",
    "                \n",
    "                # measure test time\n",
    "                start_wall_time_test = time.time()\n",
    "                start_cpu_time_test = time.process_time()\n",
    "                \n",
    "                y_train_pred_hs_rf = hs_rf.predict(X_train)\n",
    "                y_test_pred_hs_rf = hs_rf.predict(X_test)\n",
    "                \n",
    "                end_wall_time_test = time.time()\n",
    "                end_cpu_time_test = time.process_time()\n",
    "\n",
    "                classification_results = pd.concat([classification_results, pd.DataFrame({\"task\": [\"classification\"], \n",
    "                                                                            \"dataset\": [task[0]],\n",
    "                                                                            \"boot_iter\": [samp],\n",
    "                                                                            \"algorithm\": [\"HS-RF\"],\n",
    "                                                                            \"scoring\": [\"AUC\"],\n",
    "                                                                            \"n_trees\": [m],\n",
    "                                                                            \"regularization\": [best_hs_reg], # HS regression parameter (lambda)\n",
    "                                                                            \"train_score\": [roc_auc_score(y_train, y_train_pred_hs_rf)],\n",
    "                                                                            \"test_score\": [roc_auc_score(y_test, y_test_pred_hs_rf)],\n",
    "                                                                            \"train_wall_time\": [end_wall_time_train - start_wall_time_train],\n",
    "                                                                            \"test_wall_time\": [end_wall_time_test - start_wall_time_test],\n",
    "                                                                            \"train_cpu_time\": [end_cpu_time_train - start_cpu_time_train],\n",
    "                                                                            \"test_cpu_time\": [end_cpu_time_test - start_cpu_time_test],\n",
    "                                                                            \"tunning_wall_time\": [end_wall_time_tunning - start_wall_time_tunning], \n",
    "                                                                            \"tunning_cpu_time\": [end_cpu_time_tunning - start_cpu_time_tunning]})])\n",
    "                \n",
    "                ### BART (doesn't use tunning - takes to long/performs the best anyway) ###\n",
    "                \n",
    "                # measure train time\n",
    "                start_wall_time_train = time.time()\n",
    "                start_cpu_time_train = time.process_time()\n",
    "\n",
    "                bart = SklearnModel(n_trees = m);\n",
    "                bart.fit(X_train, y_train);\n",
    "\n",
    "                end_wall_time_train = time.time()\n",
    "                end_cpu_time_train = time.process_time()\n",
    "                \n",
    "                # measure test time\n",
    "                start_wall_time_test = time.time()\n",
    "                start_cpu_time_test = time.process_time()\n",
    "\n",
    "                bart_train_pred = np.round(bart.predict(X_train));\n",
    "                bart_test_pred = np.round(bart.predict(X_test));\n",
    "\n",
    "                end_wall_time_test = time.time()\n",
    "                end_cpu_time_test = time.process_time()\n",
    "\n",
    "                classification_results = pd.concat([classification_results, pd.DataFrame({\"task\": [\"classification\"], \n",
    "                                                                                \"dataset\": [task[0]],\n",
    "                                                                                \"boot_iter\": [samp],\n",
    "                                                                                \"algorithm\": [\"BART\"],\n",
    "                                                                                \"scoring\": [\"AUC\"],\n",
    "                                                                                \"n_trees\": [m],\n",
    "                                                                                \"regularization\": [\"None\"],\n",
    "                                                                                \"train_score\": [roc_auc_score(y_train, bart_train_pred)],\n",
    "                                                                                \"test_score\": [roc_auc_score(y_test, bart_test_pred)],\n",
    "                                                                                \"train_wall_time\": [end_wall_time_train - start_wall_time_train],\n",
    "                                                                                \"test_wall_time\": [end_wall_time_test - start_wall_time_test],\n",
    "                                                                                \"train_cpu_time\": [end_cpu_time_train - start_cpu_time_train],\n",
    "                                                                                \"test_cpu_time\": [end_cpu_time_test - start_cpu_time_test],\n",
    "                                                                            \"tunning_wall_time\": [None], \n",
    "                                                                            \"tunning_cpu_time\": [None]})])\n",
    "\n",
    "                classification_results.to_csv(\"claim_2_1_classification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ceff66c6-5ebd-4dd2-95ba-003ca8b096ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>dataset</th>\n",
       "      <th>boot_iter</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>scoring</th>\n",
       "      <th>n_trees</th>\n",
       "      <th>regularization</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_wall_time</th>\n",
       "      <th>test_wall_time</th>\n",
       "      <th>train_cpu_time</th>\n",
       "      <th>test_cpu_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classification</td>\n",
       "      <td>heart</td>\n",
       "      <td>0</td>\n",
       "      <td>RF</td>\n",
       "      <td>AUC</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0.98875</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>0.006989</td>\n",
       "      <td>0.001718</td>\n",
       "      <td>1.671969e+09</td>\n",
       "      <td>0.001785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classification</td>\n",
       "      <td>heart</td>\n",
       "      <td>0</td>\n",
       "      <td>RF-MTRY</td>\n",
       "      <td>AUC</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.7550</td>\n",
       "      <td>1.423662</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>1.671969e+09</td>\n",
       "      <td>0.021671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classification</td>\n",
       "      <td>heart</td>\n",
       "      <td>0</td>\n",
       "      <td>RF-DEPTH</td>\n",
       "      <td>AUC</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0.98750</td>\n",
       "      <td>0.8025</td>\n",
       "      <td>1.184656</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>1.671969e+09</td>\n",
       "      <td>0.018803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classification</td>\n",
       "      <td>heart</td>\n",
       "      <td>0</td>\n",
       "      <td>HS-RF</td>\n",
       "      <td>AUC</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0.97000</td>\n",
       "      <td>0.7850</td>\n",
       "      <td>0.192192</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>1.671969e+09</td>\n",
       "      <td>0.001345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classification</td>\n",
       "      <td>heart</td>\n",
       "      <td>0</td>\n",
       "      <td>BART</td>\n",
       "      <td>AUC</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0.87375</td>\n",
       "      <td>0.7925</td>\n",
       "      <td>13.438468</td>\n",
       "      <td>3.532102</td>\n",
       "      <td>1.671969e+09</td>\n",
       "      <td>3.532103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classification</td>\n",
       "      <td>heart</td>\n",
       "      <td>4</td>\n",
       "      <td>RF</td>\n",
       "      <td>AUC</td>\n",
       "      <td>500</td>\n",
       "      <td>None</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.279871</td>\n",
       "      <td>0.051102</td>\n",
       "      <td>1.671968e+09</td>\n",
       "      <td>0.051102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classification</td>\n",
       "      <td>heart</td>\n",
       "      <td>4</td>\n",
       "      <td>RF-MTRY</td>\n",
       "      <td>AUC</td>\n",
       "      <td>500</td>\n",
       "      <td>None</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.8425</td>\n",
       "      <td>14.501168</td>\n",
       "      <td>0.050912</td>\n",
       "      <td>1.671968e+09</td>\n",
       "      <td>0.050912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classification</td>\n",
       "      <td>heart</td>\n",
       "      <td>4</td>\n",
       "      <td>RF-DEPTH</td>\n",
       "      <td>AUC</td>\n",
       "      <td>500</td>\n",
       "      <td>None</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.8300</td>\n",
       "      <td>14.272821</td>\n",
       "      <td>0.050490</td>\n",
       "      <td>1.671968e+09</td>\n",
       "      <td>0.050491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classification</td>\n",
       "      <td>heart</td>\n",
       "      <td>4</td>\n",
       "      <td>HS-RF</td>\n",
       "      <td>AUC</td>\n",
       "      <td>500</td>\n",
       "      <td>None</td>\n",
       "      <td>0.90375</td>\n",
       "      <td>0.8350</td>\n",
       "      <td>8.633624</td>\n",
       "      <td>0.050650</td>\n",
       "      <td>1.671968e+09</td>\n",
       "      <td>0.050651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classification</td>\n",
       "      <td>heart</td>\n",
       "      <td>4</td>\n",
       "      <td>BART</td>\n",
       "      <td>AUC</td>\n",
       "      <td>500</td>\n",
       "      <td>None</td>\n",
       "      <td>0.84375</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>13.854884</td>\n",
       "      <td>3.579424</td>\n",
       "      <td>1.671968e+09</td>\n",
       "      <td>3.579432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>675 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              task dataset boot_iter algorithm scoring n_trees regularization  \\\n",
       "0   classification   heart         0        RF     AUC      10           None   \n",
       "0   classification   heart         0   RF-MTRY     AUC      10           None   \n",
       "0   classification   heart         0  RF-DEPTH     AUC      10           None   \n",
       "0   classification   heart         0     HS-RF     AUC      10           None   \n",
       "0   classification   heart         0      BART     AUC      10           None   \n",
       "..             ...     ...       ...       ...     ...     ...            ...   \n",
       "0   classification   heart         4        RF     AUC     500           None   \n",
       "0   classification   heart         4   RF-MTRY     AUC     500           None   \n",
       "0   classification   heart         4  RF-DEPTH     AUC     500           None   \n",
       "0   classification   heart         4     HS-RF     AUC     500           None   \n",
       "0   classification   heart         4      BART     AUC     500           None   \n",
       "\n",
       "    train_score  test_score  train_wall_time  test_wall_time  train_cpu_time  \\\n",
       "0       0.98875      0.7650         0.006989        0.001718    1.671969e+09   \n",
       "0       1.00000      0.7550         1.423662        0.001805    1.671969e+09   \n",
       "0       0.98750      0.8025         1.184656        0.001708    1.671969e+09   \n",
       "0       0.97000      0.7850         0.192192        0.001345    1.671969e+09   \n",
       "0       0.87375      0.7925        13.438468        3.532102    1.671969e+09   \n",
       "..          ...         ...              ...             ...             ...   \n",
       "0       1.00000      0.8625         0.279871        0.051102    1.671968e+09   \n",
       "0       1.00000      0.8425        14.501168        0.050912    1.671968e+09   \n",
       "0       1.00000      0.8300        14.272821        0.050490    1.671968e+09   \n",
       "0       0.90375      0.8350         8.633624        0.050650    1.671968e+09   \n",
       "0       0.84375      0.8625        13.854884        3.579424    1.671968e+09   \n",
       "\n",
       "    test_cpu_time  \n",
       "0        0.001785  \n",
       "0        0.021671  \n",
       "0        0.018803  \n",
       "0        0.001345  \n",
       "0        3.532103  \n",
       "..            ...  \n",
       "0        0.051102  \n",
       "0        0.050912  \n",
       "0        0.050491  \n",
       "0        0.050651  \n",
       "0        3.579432  \n",
       "\n",
       "[675 rows x 13 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(classification_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlds",
   "language": "python",
   "name": "mlds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
