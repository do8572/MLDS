{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claim 1.1 HS Improves Predictive performance of Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib as mpl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import export_text, DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import imodels\n",
    "from imodels.util.data_util import get_clean_dataset # this was used to get the datasets\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "# cross-validation of models\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import roc_auc_score, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# timing algorithm execution\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repositories used for tests (location: paper_autors_repo/config/shrinkage/models.py) - tuki sem skopiral samo ker je lazje najti\n",
    "\n",
    "DATASETS_CLASSIFICATION = [\n",
    "    # classification datasets from original random forests paper\n",
    "    # page 9: https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf\n",
    "    (\"heart\", \"heart\", 'imodels'),\n",
    "    (\"breast-cancer\", \"breast_cancer\", 'imodels'), # this is the wrong breast-cancer dataset (https://new.openml.org/search?type=data&sort=runs&id=13&status=active)\n",
    "    (\"haberman\", \"haberman\", 'imodels'),\n",
    "    (\"ionosphere\", \"ionosphere\", 'pmlb'),\n",
    "    (\"diabetes\", \"diabetes\", \"pmlb\"),\n",
    "    (\"german-credit\", \"german\", \"pmlb\"),\n",
    "    (\"juvenile\", \"juvenile_clean\", 'imodels'),\n",
    "    (\"recidivism\", \"compas_two_year_clean\", 'imodels'),\n",
    "]\n",
    "\n",
    "DATASETS_REGRESSION = [\n",
    "    ('friedman1', 'friedman1', 'synthetic'),\n",
    "    ('friedman3', 'friedman3', 'synthetic'),\n",
    "    (\"diabetes-regr\", \"diabetes\", 'sklearn'),\n",
    "    # missing red-wine and geographical music added later\n",
    "    ('abalone', '183', 'openml'),\n",
    "    (\"satellite-image\", \"294_satellite_image\", 'pmlb'),\n",
    "    (\"california-housing\", \"california_housing\", 'sklearn'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_classification = {}\n",
    "\n",
    "# load datasets\n",
    "for task in DATASETS_CLASSIFICATION:\n",
    "    X, y, feature_names = get_clean_dataset(task[1], data_source = task[2])\n",
    "    df = pd.DataFrame(X, columns=feature_names)\n",
    "    df[\"label\"] = y\n",
    "    tasks_classification[task[0]] = df\n",
    "    \n",
    "tasks_regression = {}\n",
    "\n",
    "# load datasets\n",
    "for task in DATASETS_REGRESSION:\n",
    "    X, y, feature_names = get_clean_dataset(task[1], data_source = task[2])\n",
    "    df = pd.DataFrame(X, columns=feature_names)\n",
    "    df[\"label\"] = y\n",
    "    tasks_regression[task[0]] = df\n",
    "    \n",
    "# add missing datasets (not present in code)\n",
    "# red-wine dataset\n",
    "wine = pd.read_csv(\"data/missing_data/winequality-red.csv\", sep = \";\")\n",
    "wine = (wine-wine.mean())/wine.std()\n",
    "wine.rename(columns = {'quality':'label'}, inplace = True)\n",
    "\n",
    "tasks_regression[\"red-wine\"] = wine\n",
    "DATASETS_REGRESSION.append((\"red-wine\", \"red-wine\", \"None\"))\n",
    "\n",
    "# geographical-music dataset (omitted for now since it is a 2D output dataset (RF should and can predict latitude/longitude))\n",
    "# 116 & 117 are part of label\n",
    "music = pd.read_csv(\"data/missing_data/geo-music-big.txt\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef pick_alpha(X, y, number_of_leaves, dt_class, scorer):\\n    path = dt_class(max_leaf_nodes=number_of_leaves).cost_complexity_pruning_path(X, y)\\n    alphas = path[\"ccp_alphas\"]\\n    \\n    cv_scores = {}\\n    \\n    for alpha in alphas:\\n        hs_skf = StratifiedKFold(n_splits=3)\\n        cv_scores[alpha] = []\\n        for j, (cv_train_index, cv_val_index) in enumerate(hs_skf.split(X, y)):\\n            X_cv_train, y_cv_train = X[cv_train_index, :], y[cv_train_index]\\n            X_cv_val, y_cv_val = X[cv_val_index, :], y[cv_val_index]\\n            mccp = dt_class(ccp_alpha=alpha).fit(X_cv_train, y_cv_train)\\n            y_val_pred = mccp.predict(X_cv_val)\\n            cv_scores[alpha].append(scorer(y_cv_val, y_val_pred))\\n    \\n    cv_scores = {reg_param: np.mean(cv_scores[reg_param]) for reg_param in cv_scores.keys()}\\n    best_score = np.max([cv_scores[reg_param] for reg_param in cv_scores.keys()])\\n    best_param = [reg_param for reg_param in cv_scores.keys() if cv_scores[reg_param] == best_score][0]\\n    \\n    return best_param\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def leaf_count(dt):\n",
    "    tree = dt.tree_\n",
    "    num_leaves = 0\n",
    "\n",
    "    for i in range(tree.node_count):\n",
    "        if tree.children_left[i] > 0 or tree.children_right[i] > 0:\n",
    "            num_leaves += 1\n",
    "\n",
    "    return num_leaves\n",
    "\n",
    "# fix-up alpha\n",
    "def pick_alpha(X, y, number_of_leaves, dt_class):\n",
    "    path = dt_class().cost_complexity_pruning_path(X, y)\n",
    "    alphas = path[\"ccp_alphas\"]\n",
    "\n",
    "    leaf_cnts = []\n",
    "\n",
    "    for alpha in alphas:\n",
    "        mccp = dt_class(ccp_alpha=alpha).fit(X, y)\n",
    "        leaf_cnts.append(np.abs(number_of_leaves - leaf_count(mccp)))\n",
    "    idx = np.argmin(leaf_cnts)\n",
    "\n",
    "    return alphas[idx]\n",
    "\n",
    "\"\"\"\n",
    "def pick_alpha(X, y, number_of_leaves, dt_class, scorer):\n",
    "    path = dt_class(max_leaf_nodes=number_of_leaves).cost_complexity_pruning_path(X, y)\n",
    "    alphas = path[\"ccp_alphas\"]\n",
    "    \n",
    "    cv_scores = {}\n",
    "    \n",
    "    for alpha in alphas:\n",
    "        hs_skf = StratifiedKFold(n_splits=3)\n",
    "        cv_scores[alpha] = []\n",
    "        for j, (cv_train_index, cv_val_index) in enumerate(hs_skf.split(X, y)):\n",
    "            X_cv_train, y_cv_train = X[cv_train_index, :], y[cv_train_index]\n",
    "            X_cv_val, y_cv_val = X[cv_val_index, :], y[cv_val_index]\n",
    "            mccp = dt_class(ccp_alpha=alpha).fit(X_cv_train, y_cv_train)\n",
    "            y_val_pred = mccp.predict(X_cv_val)\n",
    "            cv_scores[alpha].append(scorer(y_cv_val, y_val_pred))\n",
    "    \n",
    "    cv_scores = {reg_param: np.mean(cv_scores[reg_param]) for reg_param in cv_scores.keys()}\n",
    "    best_score = np.max([cv_scores[reg_param] for reg_param in cv_scores.keys()])\n",
    "    best_param = [reg_param for reg_param in cv_scores.keys() if cv_scores[reg_param] == best_score][0]\n",
    "    \n",
    "    return best_param\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 A) Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: recidivism, Sample: 9, Fold 2d 2\r"
     ]
    }
   ],
   "source": [
    "# number of leafs used in paper\n",
    "num_of_leaves = [2, 4, 8, 12, 15, 20, 24, 28, 30, 32]\n",
    "# reuglarization parameter\n",
    "reg_hs = [0.1, 1.0, 10.0, 25.0, 50.0, 100.0]\n",
    "\n",
    "# Potential problem HS appeared to be choosen via CV (hopefully they split the dataset before hand)\n",
    "NUM_OF_BOOTSTRAP_SAMPS = 10\n",
    "classification_results = pd.DataFrame(columns = [\"task\", \"dataset\", \"boot_iter\", \"algorithm\", \"scoring\", \"n_leaves\", \"max_leaves\", \"regularization\", \"train_score\", \"test_score\", \\\n",
    "                                                 \"train_wall_time\", \"test_wall_time\", \"train_cpu_time\", \"test_cpu_time\", \"tunning_wall_time\", \"tunning_cpu_time\"])\n",
    "\n",
    "for task in DATASETS_CLASSIFICATION:\n",
    "    for samp in range(NUM_OF_BOOTSTRAP_SAMPS):\n",
    "        skf = StratifiedKFold(n_splits=3)\n",
    "        X, y = np.array(tasks_classification[task[0]].drop(\"label\", axis = 1)), np.array(tasks_classification[task[0]][\"label\"])\n",
    "        for i, (train_index, test_index) in enumerate(skf.split(tasks_classification[task[0]], tasks_classification[task[0]][\"label\"])):\n",
    "            print(f\"Dataset: {task[0]}, Sample: {samp}, Fold {i}\", end = \"\\r\")\n",
    "\n",
    "            X_train, y_train = X[train_index, :], y[train_index]\n",
    "            X_test, y_test = X[test_index, :], y[test_index]\n",
    "\n",
    "            for m in num_of_leaves:\n",
    "                ### CART ###\n",
    "                \n",
    "                # measure train time\n",
    "                start_wall_time_train = time.time()\n",
    "                start_cpu_time_train = time.process_time()\n",
    "                \n",
    "                m1 = DecisionTreeClassifier(max_leaf_nodes=m).fit(X_train, y_train)\n",
    "                \n",
    "                end_wall_time_train = time.time()\n",
    "                end_cpu_time_train = time.process_time()\n",
    "                \n",
    "                # measure test time\n",
    "                start_wall_time_test = time.time()\n",
    "                start_cpu_time_test = time.process_time()\n",
    "                \n",
    "                y_train_pred_dt = m1.predict(X_train)\n",
    "                y_test_pred_dt = m1.predict(X_test)\n",
    "                \n",
    "                end_wall_time_test = time.time()\n",
    "                end_cpu_time_test = time.process_time()\n",
    "\n",
    "                classification_results = pd.concat([classification_results, pd.DataFrame({\"task\": [\"classification\"], \n",
    "                                                                            \"dataset\": [task[0]],\n",
    "                                                                            \"boot_iter\": [samp],\n",
    "                                                                            \"algorithm\": [\"DT\"],\n",
    "                                                                            \"scoring\": [\"AUC\"],\n",
    "                                                                            \"n_leaves\": [leaf_count(m1)],\n",
    "                                                                            \"max_leaves\": [m],\n",
    "                                                                            \"regularization\": [\"None\"],\n",
    "                                                                            \"train_score\": [roc_auc_score(y_train, y_train_pred_dt)],\n",
    "                                                                            \"test_score\": [roc_auc_score(y_test, y_test_pred_dt)],\n",
    "                                                                            \"train_wall_time\": [end_wall_time_train - start_wall_time_train],\n",
    "                                                                            \"test_wall_time\": [end_wall_time_test - start_wall_time_test],\n",
    "                                                                            \"train_cpu_time\": [end_cpu_time_train - start_cpu_time_train],\n",
    "                                                                            \"test_cpu_time\": [end_cpu_time_test - start_cpu_time_test],\n",
    "                                                                            \"tunning_wall_time\": [None], \n",
    "                                                                            \"tunning_cpu_time\": [None]})])\n",
    "\n",
    "                ### CART with CCP ###\n",
    "                \n",
    "                # measure tunning time\n",
    "                start_wall_time_tunning = time.time()\n",
    "                start_cpu_time_tunning = time.process_time()\n",
    "                \n",
    "                best_alpha = pick_alpha(X_train, y_train, m, DecisionTreeClassifier)\n",
    "                \n",
    "                end_wall_time_tunning = time.time()\n",
    "                end_cpu_time_tunning = time.process_time()\n",
    "                \n",
    "                # measure train time\n",
    "                start_wall_time_train = time.time()\n",
    "                start_cpu_time_train = time.process_time()\n",
    "                \n",
    "                mccp = DecisionTreeClassifier(ccp_alpha=best_alpha).fit(X_train, y_train)\n",
    "                \n",
    "                end_wall_time_train = time.time()\n",
    "                end_cpu_time_train = time.process_time()\n",
    "                \n",
    "                # measure test time\n",
    "                start_wall_time_test = time.time()\n",
    "                start_cpu_time_test = time.process_time()\n",
    "                \n",
    "                y_train_pred_ccp = mccp.predict(X_train)\n",
    "                y_test_pred_ccp = mccp.predict(X_test)\n",
    "                \n",
    "                end_wall_time_test = time.time()\n",
    "                end_cpu_time_test = time.process_time()\n",
    "\n",
    "                classification_results = pd.concat([classification_results, pd.DataFrame({\"task\": [\"classification\"], \n",
    "                                                                            \"dataset\": [task[0]],\n",
    "                                                                            \"boot_iter\": [samp],\n",
    "                                                                            \"algorithm\": [\"CCP\"],\n",
    "                                                                            \"scoring\": [\"AUC\"],\n",
    "                                                                            \"n_leaves\": [leaf_count(mccp)],\n",
    "                                                                            \"max_leaves\": [m],\n",
    "                                                                            \"regularization\": [best_alpha],\n",
    "                                                                            \"train_score\": [roc_auc_score(y_train, y_train_pred_ccp)],\n",
    "                                                                            \"test_score\": [roc_auc_score(y_test, y_test_pred_ccp)],\n",
    "                                                                            \"train_wall_time\": [end_wall_time_train - start_wall_time_train],\n",
    "                                                                            \"test_wall_time\": [end_wall_time_test - start_wall_time_test],\n",
    "                                                                            \"train_cpu_time\": [end_cpu_time_train - start_cpu_time_train],\n",
    "                                                                            \"test_cpu_time\": [end_cpu_time_test - start_cpu_time_test],\n",
    "                                                                            \"tunning_wall_time\": [end_wall_time_tunning - start_wall_time_tunning], \n",
    "                                                                            \"tunning_cpu_time\": [end_cpu_time_tunning - start_cpu_time_tunning]})])\n",
    "\n",
    "                ### C4.5 DT ###\n",
    "                \"\"\"\n",
    "                mc45 = imodels.C45TreeClassifier().fit(X_train, y_train)\n",
    "                y_train_pred_c45 = mc45.predict(X_train)\n",
    "                y_test_pred_c45 = mc45.predict(X_test)\n",
    "\n",
    "                classification_results = pd.concat([classification_results, pd.DataFrame({\"task\": [\"classification\"], \n",
    "                                                                            \"dataset\": [task[0]],\n",
    "                                                                            \"boot_iter\": [samp],\n",
    "                                                                            \"algorithm\": [\"C4.5\"],\n",
    "                                                                            \"scoring\": [\"AUC\"],\n",
    "                                                                            \"n_leaves\": [leaf_count(mc45.estimator_)],\n",
    "                                                                            \"max_leaves\": [m],\n",
    "                                                                            \"regularization\": [\"None\"],\n",
    "                                                                            \"train_score\": [roc_auc_score(y_train, y_train_pred_c45)],\n",
    "                                                                            \"test_score\": [roc_auc_score(y_test, y_test_pred_c45)]})])\n",
    "                \"\"\"\n",
    "\n",
    "                # TODO: GOSDT ###\n",
    "                \n",
    "                ### Hierarchical shrinkage ###\n",
    "                \n",
    "                # measure tunning time\n",
    "                start_wall_time_tunning = time.time()\n",
    "                start_cpu_time_tunning = time.process_time()\n",
    "                \n",
    "                cv_scores = {}\n",
    "                for reg_param in reg_hs:\n",
    "                    hs_skf = StratifiedKFold(n_splits=3)\n",
    "                    cv_scores[reg_param] = []\n",
    "                    for j, (cv_train_index, cv_val_index) in enumerate(hs_skf.split(X_train, y_train)):\n",
    "                        X_cv_train, y_cv_train = X[cv_train_index, :], y[cv_train_index]\n",
    "                        X_cv_val, y_cv_val = X[cv_val_index, :], y[cv_val_index]\n",
    "                        hs_cv_dt = DecisionTreeClassifier(max_leaf_nodes=m)\n",
    "                        hs_cv_dt.fit(X_cv_train, y_cv_train)\n",
    "                        hs_cv_dt = imodels.HSTreeClassifier(hs_cv_dt, reg_param=reg_param)\n",
    "                        y_val_pred = hs_cv_dt.predict(X_cv_val)\n",
    "                        cv_scores[reg_param].append(roc_auc_score(y_cv_val, y_val_pred))\n",
    "                cv_scores = {reg_param: np.mean(cv_scores[reg_param]) for reg_param in cv_scores.keys()}\n",
    "                best_score = np.max([cv_scores[reg_param] for reg_param in cv_scores.keys()])\n",
    "                best_param = [reg_param for reg_param in cv_scores.keys() if cv_scores[reg_param] == best_score][0]\n",
    "                hs_reg_param = best_param\n",
    "                \n",
    "                end_wall_time_tunning = time.time()\n",
    "                end_cpu_time_tunning = time.process_time()\n",
    "\n",
    "                # evaluation of improvements offered by hierarchical shrinkage model\n",
    "                # measure train time\n",
    "                start_wall_time_train = time.time()\n",
    "                start_cpu_time_train = time.process_time()\n",
    "                \n",
    "                mshrunk = imodels.HSTreeClassifier(deepcopy(m1), reg_param=hs_reg_param) #.fit(X_train, y_train)\n",
    "                \n",
    "                end_wall_time_train = time.time()\n",
    "                end_cpu_time_train = time.process_time()\n",
    "                \n",
    "                # measure test time\n",
    "                start_wall_time_test = time.time()\n",
    "                start_cpu_time_test = time.process_time()\n",
    "                \n",
    "                y_train_pred_shrunk = mshrunk.predict(X_train)\n",
    "                y_test_pred_shrunk = mshrunk.predict(X_test)\n",
    "                \n",
    "                end_wall_time_test = time.time()\n",
    "                end_cpu_time_test = time.process_time()\n",
    "\n",
    "                classification_results = pd.concat([classification_results, pd.DataFrame({\"task\": [\"classification\"], \n",
    "                                                                            \"dataset\": [task[0]],\n",
    "                                                                            \"boot_iter\": [samp],\n",
    "                                                                            \"algorithm\": [\"HS (CART)\"],\n",
    "                                                                            \"scoring\": [\"AUC\"],\n",
    "                                                                            \"n_leaves\": [leaf_count(mshrunk.estimator_)],\n",
    "                                                                            \"max_leaves\": [m],\n",
    "                                                                            \"regularization\": [hs_reg_param],\n",
    "                                                                            \"train_score\": [roc_auc_score(y_train, y_train_pred_shrunk)],\n",
    "                                                                            \"test_score\": [roc_auc_score(y_test, y_test_pred_shrunk)],\n",
    "                                                                            \"train_wall_time\": [end_wall_time_train - start_wall_time_train],\n",
    "                                                                            \"test_wall_time\": [end_wall_time_test - start_wall_time_test],\n",
    "                                                                            \"train_cpu_time\": [end_cpu_time_train - start_cpu_time_train],\n",
    "                                                                            \"test_cpu_time\": [end_cpu_time_test - start_cpu_time_test],\n",
    "                                                                            \"tunning_wall_time\": [end_wall_time_tunning - start_wall_time_tunning], \n",
    "                                                                            \"tunning_cpu_time\": [end_cpu_time_tunning - start_cpu_time_tunning]})])\n",
    "\n",
    "\n",
    "                ### Hierarchical shrinkage (CCP) ###\n",
    "            \n",
    "                # measure tunning time\n",
    "                start_wall_time_tunning = time.time()\n",
    "                start_cpu_time_tunning = time.process_time()\n",
    "                \n",
    "                cv_scores = {}\n",
    "                for reg_param in reg_hs:\n",
    "                    hs_skf = StratifiedKFold(n_splits=3)\n",
    "                    cv_scores[reg_param] = []\n",
    "                    for j, (cv_train_index, cv_val_index) in enumerate(hs_skf.split(X_train, y_train)):\n",
    "                        X_cv_train, y_cv_train = X[cv_train_index, :], y[cv_train_index]\n",
    "                        X_cv_val, y_cv_val = X[cv_val_index, :], y[cv_val_index]\n",
    "                        hs_cv_ccp = DecisionTreeClassifier(max_leaf_nodes=m, ccp_alpha=pick_alpha(X_cv_train, y_cv_train, m, DecisionTreeClassifier))\n",
    "                        hs_cv_ccp.fit(X_cv_train, y_cv_train)\n",
    "                        hs_cv_ccp = imodels.HSTreeClassifier(hs_cv_ccp, reg_param=reg_param)\n",
    "                        y_val_pred = hs_cv_dt.predict(X_cv_val)\n",
    "                        cv_scores[reg_param].append(roc_auc_score(y_cv_val, y_val_pred))\n",
    "                cv_scores = {reg_param: np.mean(cv_scores[reg_param]) for reg_param in cv_scores.keys()}\n",
    "                best_score = np.max([cv_scores[reg_param] for reg_param in cv_scores.keys()])\n",
    "                best_param = [reg_param for reg_param in cv_scores.keys() if cv_scores[reg_param] == best_score][0]\n",
    "                hs_reg_param = best_param\n",
    "                \n",
    "                end_wall_time_tunning = time.time()\n",
    "                end_cpu_time_tunning = time.process_time()\n",
    "\n",
    "                # evaluation of improvements offered by hierarchical shrinkage model\n",
    "                \n",
    "                # measure train time\n",
    "                start_wall_time_train = time.time()\n",
    "                start_cpu_time_train = time.process_time()\n",
    "                \n",
    "                mshrunk = imodels.HSTreeClassifier(deepcopy(mccp), reg_param=hs_reg_param) #.fit(X_train, y_train)\n",
    "                \n",
    "                end_wall_time_train = time.time()\n",
    "                end_cpu_time_train = time.process_time()\n",
    "                \n",
    "                # measure test time\n",
    "                start_wall_time_test = time.time()\n",
    "                start_cpu_time_test = time.process_time()\n",
    "                \n",
    "                y_train_pred_shrunk = mshrunk.predict(X_train)\n",
    "                y_test_pred_shrunk = mshrunk.predict(X_test)\n",
    "                \n",
    "                end_wall_time_test = time.time()\n",
    "                end_cpu_time_test = time.process_time()\n",
    "\n",
    "                classification_results = pd.concat([classification_results, pd.DataFrame({\"task\": [\"classification\"], \n",
    "                                                                            \"dataset\": [task[0]],\n",
    "                                                                            \"boot_iter\": [samp],\n",
    "                                                                            \"algorithm\": [\"HS (CART-CCP)\"],\n",
    "                                                                            \"scoring\": [\"AUC\"],\n",
    "                                                                            \"n_leaves\": [leaf_count(mshrunk.estimator_)],\n",
    "                                                                            \"max_leaves\": [m],\n",
    "                                                                            \"regularization\": [hs_reg_param],\n",
    "                                                                            \"train_score\": [roc_auc_score(y_train, y_train_pred_shrunk)],\n",
    "                                                                            \"test_score\": [roc_auc_score(y_test, y_test_pred_shrunk)],\n",
    "                                                                            \"train_wall_time\": [end_wall_time_train - start_wall_time_train],\n",
    "                                                                            \"test_wall_time\": [end_wall_time_test - start_wall_time_test],\n",
    "                                                                            \"train_cpu_time\": [end_cpu_time_train - start_cpu_time_train],\n",
    "                                                                            \"test_cpu_time\": [end_cpu_time_test - start_cpu_time_test],\n",
    "                                                                            \"tunning_wall_time\": [end_wall_time_tunning - start_wall_time_tunning], \n",
    "                                                                            \"tunning_cpu_time\": [end_cpu_time_tunning - start_cpu_time_tunning]})])\n",
    "\n",
    "\n",
    "                classification_results.to_csv(\"claim_1_1_classification.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 B) Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: abalone, Sample: 3, Fold 1Fold 2\r"
     ]
    }
   ],
   "source": [
    "# number of leafs used in paper\n",
    "num_of_leaves = [2, 4, 8, 12, 15, 20, 24, 28, 30, 32]\n",
    "# reuglarization parameter\n",
    "reg_hs = [0.1, 1.0, 10.0, 25.0, 50.0, 100.0]\n",
    "\n",
    "# Potential problem HS appeared to be choosen via CV (hopefully they split the dataset before hand)\n",
    "NUM_OF_BOOTSTRAP_SAMPS = 5\n",
    "regression_results = pd.DataFrame(columns = [\"task\", \"dataset\", \"boot_iter\", \"algorithm\", \"scoring\", \"n_leaves\", \"max_leaves\", \"regularization\", \"train_score\", \"test_score\", \\\n",
    "                                                 \"train_wall_time\", \"test_wall_time\", \"train_cpu_time\", \"test_cpu_time\", \"tunning_wall_time\", \"tunning_cpu_time\"])\n",
    "\n",
    "for task in DATASETS_REGRESSION:\n",
    "    for samp in range(NUM_OF_BOOTSTRAP_SAMPS):\n",
    "        skf = KFold(n_splits=3)\n",
    "        X, y = np.array(tasks_regression[task[0]].drop(\"label\", axis = 1)), np.array(tasks_regression[task[0]][\"label\"])\n",
    "        for i, (train_index, test_index) in enumerate(skf.split(tasks_regression[task[0]], tasks_regression[task[0]][\"label\"])):\n",
    "            print(f\"Dataset: {task[0]}, Sample: {samp}, Fold {i}\", end = \"\\r\")\n",
    "\n",
    "            X_train, y_train = X[train_index, :], y[train_index]\n",
    "            X_test, y_test = X[test_index, :], y[test_index]\n",
    "\n",
    "            for m in num_of_leaves:\n",
    "                ### CART ###\n",
    "                \n",
    "                # measure train time\n",
    "                start_wall_time_train = time.time()\n",
    "                start_cpu_time_train = time.process_time()\n",
    "                \n",
    "                m1 = DecisionTreeRegressor(max_leaf_nodes=m).fit(X_train, y_train)\n",
    "                \n",
    "                end_wall_time_train = time.time()\n",
    "                end_cpu_time_train = time.process_time()\n",
    "                \n",
    "                # measure test time\n",
    "                start_wall_time_test = time.time()\n",
    "                start_cpu_time_test = time.process_time()\n",
    "                \n",
    "                y_train_pred_dt = m1.predict(X_train)\n",
    "                y_test_pred_dt = m1.predict(X_test)\n",
    "                \n",
    "                end_wall_time_test = time.time()\n",
    "                end_cpu_time_test = time.process_time()\n",
    "\n",
    "                regression_results = pd.concat([regression_results, pd.DataFrame({\"task\": [\"regression\"], \n",
    "                                                                            \"dataset\": [task[0]],\n",
    "                                                                            \"boot_iter\": [samp],\n",
    "                                                                            \"algorithm\": [\"DT\"],\n",
    "                                                                            \"scoring\": [\"R2\"],\n",
    "                                                                            \"n_leaves\": [leaf_count(m1)],\n",
    "                                                                            \"max_leaves\": [m],\n",
    "                                                                            \"regularization\": [\"None\"],\n",
    "                                                                            \"train_score\": [r2_score(y_train, y_train_pred_dt)],\n",
    "                                                                            \"test_score\": [r2_score(y_test, y_test_pred_dt)],\n",
    "                                                                            \"train_wall_time\": [end_wall_time_train - start_wall_time_train],\n",
    "                                                                            \"test_wall_time\": [end_wall_time_test - start_wall_time_test],\n",
    "                                                                            \"train_cpu_time\": [end_cpu_time_train - start_cpu_time_train],\n",
    "                                                                            \"test_cpu_time\": [end_cpu_time_test - start_cpu_time_test],\n",
    "                                                                            \"tunning_wall_time\": [None], \n",
    "                                                                            \"tunning_cpu_time\": [None]})])\n",
    "\n",
    "                ### CART with CCP ###\n",
    "                \n",
    "                # measure tunning time\n",
    "                start_wall_time_tunning = time.time()\n",
    "                start_cpu_time_tunning = time.process_time()\n",
    "                \n",
    "                best_alpha = pick_alpha(X_train, y_train, m, DecisionTreeRegressor)\n",
    "                \n",
    "                end_wall_time_tunning = time.time()\n",
    "                end_cpu_time_tunning = time.process_time()\n",
    "                \n",
    "                # measure train time\n",
    "                start_wall_time_train = time.time()\n",
    "                start_cpu_time_train = time.process_time()\n",
    "                \n",
    "                mccp = DecisionTreeRegressor(ccp_alpha=best_alpha).fit(X_train, y_train)\n",
    "                \n",
    "                end_wall_time_train = time.time()\n",
    "                end_cpu_time_train = time.process_time()\n",
    "                \n",
    "                # measure test time\n",
    "                start_wall_time_test = time.time()\n",
    "                start_cpu_time_test = time.process_time()\n",
    "                \n",
    "                y_train_pred_ccp = mccp.predict(X_train)\n",
    "                y_test_pred_ccp = mccp.predict(X_test)\n",
    "                \n",
    "                end_wall_time_test = time.time()\n",
    "                end_cpu_time_test = time.process_time()\n",
    "\n",
    "                regression_results = pd.concat([regression_results, pd.DataFrame({\"task\": [\"regression\"], \n",
    "                                                                            \"dataset\": [task[0]],\n",
    "                                                                            \"boot_iter\": [samp],\n",
    "                                                                            \"algorithm\": [\"CCP\"],\n",
    "                                                                            \"scoring\": [\"R2\"],\n",
    "                                                                            \"n_leaves\": [leaf_count(mccp)],\n",
    "                                                                            \"max_leaves\": [m],\n",
    "                                                                            \"regularization\": [best_alpha],\n",
    "                                                                            \"train_score\": [r2_score(y_train, y_train_pred_ccp)],\n",
    "                                                                            \"test_score\": [r2_score(y_test, y_test_pred_ccp)],\n",
    "                                                                            \"train_wall_time\": [end_wall_time_train - start_wall_time_train],\n",
    "                                                                            \"test_wall_time\": [end_wall_time_test - start_wall_time_test],\n",
    "                                                                            \"train_cpu_time\": [end_cpu_time_train - start_cpu_time_train],\n",
    "                                                                            \"test_cpu_time\": [end_cpu_time_test - start_cpu_time_test],\n",
    "                                                                            \"tunning_wall_time\": [end_wall_time_tunning - start_wall_time_tunning], \n",
    "                                                                            \"tunning_cpu_time\": [end_cpu_time_tunning - start_cpu_time_tunning]})])\n",
    "\n",
    "                ### C4.5 DT ###\n",
    "                \"\"\"\n",
    "                mc45 = imodels.C45TreeClassifier().fit(X_train, y_train)\n",
    "                y_train_pred_c45 = mc45.predict(X_train)\n",
    "                y_test_pred_c45 = mc45.predict(X_test)\n",
    "\n",
    "                regression_results = pd.concat([regression_results, pd.DataFrame({\"task\": [\"regression\"], \n",
    "                                                                            \"dataset\": [task[0]],\n",
    "                                                                            \"boot_iter\": [samp],\n",
    "                                                                            \"algorithm\": [\"C4.5\"],\n",
    "                                                                            \"scoring\": [\"R2\"],\n",
    "                                                                            \"n_leaves\": [leaf_count(mc45.estimator_)],\n",
    "                                                                            \"max_leaves\": [m],\n",
    "                                                                            \"regularization\": [\"None\"],\n",
    "                                                                            \"train_score\": [r2_score(y_train, y_train_pred_c45)],\n",
    "                                                                            \"test_score\": [r2_score(y_test, y_test_pred_c45)]})])\n",
    "                \"\"\"\n",
    "\n",
    "                # TODO: GOSDT ###\n",
    "                \n",
    "                ### Hierarchical shrinkage ###\n",
    "                \n",
    "                # measure tunning time\n",
    "                start_wall_time_tunning = time.time()\n",
    "                start_cpu_time_tunning = time.process_time()\n",
    "                \n",
    "                cv_scores = {}\n",
    "                for reg_param in reg_hs:\n",
    "                    hs_skf = KFold(n_splits=3)\n",
    "                    cv_scores[reg_param] = []\n",
    "                    for j, (cv_train_index, cv_val_index) in enumerate(hs_skf.split(X_train, y_train)):\n",
    "                        X_cv_train, y_cv_train = X[cv_train_index, :], y[cv_train_index]\n",
    "                        X_cv_val, y_cv_val = X[cv_val_index, :], y[cv_val_index]\n",
    "                        hs_cv_dt = DecisionTreeRegressor(max_leaf_nodes=m)\n",
    "                        hs_cv_dt.fit(X_cv_train, y_cv_train)\n",
    "                        hs_cv_dt = imodels.HSTreeRegressor(hs_cv_dt, reg_param=reg_param)\n",
    "                        y_val_pred = hs_cv_dt.predict(X_cv_val)\n",
    "                        cv_scores[reg_param].append(r2_score(y_cv_val, y_val_pred))\n",
    "                cv_scores = {reg_param: np.mean(cv_scores[reg_param]) for reg_param in cv_scores.keys()}\n",
    "                best_score = np.max([cv_scores[reg_param] for reg_param in cv_scores.keys()])\n",
    "                best_param = [reg_param for reg_param in cv_scores.keys() if cv_scores[reg_param] == best_score][0]\n",
    "                hs_reg_param = best_param\n",
    "                \n",
    "                end_wall_time_tunning = time.time()\n",
    "                end_cpu_time_tunning = time.process_time()\n",
    "\n",
    "                # evaluation of improvements offered by hierarchical shrinkage model\n",
    "                # measure train time\n",
    "                start_wall_time_train = time.time()\n",
    "                start_cpu_time_train = time.process_time()\n",
    "                \n",
    "                mshrunk = imodels.HSTreeRegressor(deepcopy(m1), reg_param=hs_reg_param) #.fit(X_train, y_train)\n",
    "                \n",
    "                end_wall_time_train = time.time()\n",
    "                end_cpu_time_train = time.process_time()\n",
    "                \n",
    "                # measure test time\n",
    "                start_wall_time_test = time.time()\n",
    "                start_cpu_time_test = time.process_time()\n",
    "                \n",
    "                y_train_pred_shrunk = mshrunk.predict(X_train)\n",
    "                y_test_pred_shrunk = mshrunk.predict(X_test)\n",
    "                \n",
    "                end_wall_time_test = time.time()\n",
    "                end_cpu_time_test = time.process_time()\n",
    "\n",
    "                regression_results = pd.concat([regression_results, pd.DataFrame({\"task\": [\"regression\"], \n",
    "                                                                            \"dataset\": [task[0]],\n",
    "                                                                            \"boot_iter\": [samp],\n",
    "                                                                            \"algorithm\": [\"HS (CART)\"],\n",
    "                                                                            \"scoring\": [\"R2\"],\n",
    "                                                                            \"n_leaves\": [leaf_count(mshrunk.estimator_)],\n",
    "                                                                            \"max_leaves\": [m],\n",
    "                                                                            \"regularization\": [hs_reg_param],\n",
    "                                                                            \"train_score\": [r2_score(y_train, y_train_pred_shrunk)],\n",
    "                                                                            \"test_score\": [r2_score(y_test, y_test_pred_shrunk)],\n",
    "                                                                            \"train_wall_time\": [end_wall_time_train - start_wall_time_train],\n",
    "                                                                            \"test_wall_time\": [end_wall_time_test - start_wall_time_test],\n",
    "                                                                            \"train_cpu_time\": [end_cpu_time_train - start_cpu_time_train],\n",
    "                                                                            \"test_cpu_time\": [end_cpu_time_test - start_cpu_time_test],\n",
    "                                                                            \"tunning_wall_time\": [end_wall_time_tunning - start_wall_time_tunning], \n",
    "                                                                            \"tunning_cpu_time\": [end_cpu_time_tunning - start_cpu_time_tunning]})])\n",
    "\n",
    "\n",
    "                ### Hierarchical shrinkage (CCP) ###\n",
    "            \n",
    "                # measure tunning time\n",
    "                start_wall_time_tunning = time.time()\n",
    "                start_cpu_time_tunning = time.process_time()\n",
    "                \n",
    "                cv_scores = {}\n",
    "                for reg_param in reg_hs:\n",
    "                    hs_skf = KFold(n_splits=3)\n",
    "                    cv_scores[reg_param] = []\n",
    "                    for j, (cv_train_index, cv_val_index) in enumerate(hs_skf.split(X_train, y_train)):\n",
    "                        X_cv_train, y_cv_train = X[cv_train_index, :], y[cv_train_index]\n",
    "                        X_cv_val, y_cv_val = X[cv_val_index, :], y[cv_val_index]\n",
    "                        hs_cv_ccp = DecisionTreeRegressor(max_leaf_nodes=m, ccp_alpha=pick_alpha(X_cv_train, y_cv_train, m, DecisionTreeRegressor))\n",
    "                        hs_cv_ccp.fit(X_cv_train, y_cv_train)\n",
    "                        hs_cv_ccp = imodels.HSTreeRegressor(hs_cv_ccp, reg_param=reg_param)\n",
    "                        y_val_pred = hs_cv_dt.predict(X_cv_val)\n",
    "                        cv_scores[reg_param].append(r2_score(y_cv_val, y_val_pred))\n",
    "                cv_scores = {reg_param: np.mean(cv_scores[reg_param]) for reg_param in cv_scores.keys()}\n",
    "                best_score = np.max([cv_scores[reg_param] for reg_param in cv_scores.keys()])\n",
    "                best_param = [reg_param for reg_param in cv_scores.keys() if cv_scores[reg_param] == best_score][0]\n",
    "                hs_reg_param = best_param\n",
    "                \n",
    "                end_wall_time_tunning = time.time()\n",
    "                end_cpu_time_tunning = time.process_time()\n",
    "\n",
    "                # evaluation of improvements offered by hierarchical shrinkage model\n",
    "                \n",
    "                # measure train time\n",
    "                start_wall_time_train = time.time()\n",
    "                start_cpu_time_train = time.process_time()\n",
    "                \n",
    "                mshrunk = imodels.HSTreeRegressor(deepcopy(mccp), reg_param=hs_reg_param) #.fit(X_train, y_train)\n",
    "                \n",
    "                end_wall_time_train = time.time()\n",
    "                end_cpu_time_train = time.process_time()\n",
    "                \n",
    "                # measure test time\n",
    "                start_wall_time_test = time.time()\n",
    "                start_cpu_time_test = time.process_time()\n",
    "                \n",
    "                y_train_pred_shrunk = mshrunk.predict(X_train)\n",
    "                y_test_pred_shrunk = mshrunk.predict(X_test)\n",
    "                \n",
    "                end_wall_time_test = time.time()\n",
    "                end_cpu_time_test = time.process_time()\n",
    "\n",
    "                regression_results = pd.concat([regression_results, pd.DataFrame({\"task\": [\"regression\"], \n",
    "                                                                            \"dataset\": [task[0]],\n",
    "                                                                            \"boot_iter\": [samp],\n",
    "                                                                            \"algorithm\": [\"HS (CART-CCP)\"],\n",
    "                                                                            \"scoring\": [\"R2\"],\n",
    "                                                                            \"n_leaves\": [leaf_count(mshrunk.estimator_)],\n",
    "                                                                            \"max_leaves\": [m],\n",
    "                                                                            \"regularization\": [hs_reg_param],\n",
    "                                                                            \"train_score\": [r2_score(y_train, y_train_pred_shrunk)],\n",
    "                                                                            \"test_score\": [r2_score(y_test, y_test_pred_shrunk)],\n",
    "                                                                            \"train_wall_time\": [end_wall_time_train - start_wall_time_train],\n",
    "                                                                            \"test_wall_time\": [end_wall_time_test - start_wall_time_test],\n",
    "                                                                            \"train_cpu_time\": [end_cpu_time_train - start_cpu_time_train],\n",
    "                                                                            \"test_cpu_time\": [end_cpu_time_test - start_cpu_time_test],\n",
    "                                                                            \"tunning_wall_time\": [end_wall_time_tunning - start_wall_time_tunning], \n",
    "                                                                            \"tunning_cpu_time\": [end_cpu_time_tunning - start_cpu_time_tunning]})])\n",
    "\n",
    "\n",
    "                regression_results.to_csv(\"claim_1_1_regression.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlds",
   "language": "python",
   "name": "mlds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "4a05bcba1dcd306d3e56e2031dba7ae2c5de928c22c5ad43dffcb831ea303041"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
